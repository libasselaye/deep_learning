{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TD3 2/2 : introduction d'un espace de représentation des mots (embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce notebook a été développé dans le cours donné par J. Velcin et J. Cugliari sur le Deep Learning à l'Université de Lyon 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On commence par charger en mémoire les données spam diffusée à l'occasion du tutoriel de A. Gramfort et A. Mueller à SciPy 2017\n",
    "https://github.com/amueller/scipy-2017-sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "with open(os.path.join(\"SMSSpamCollection.txt\")) as f:\n",
    "    lines = [line.strip().split(\"\\t\") for line in f.readlines()]\n",
    "\n",
    "text = [x[1] for x in lines]\n",
    "y = [int(x[0] == \"spam\") for x in lines]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On procède différemment cette fois en ayant recours à une fonction de hachage, sans chercher pour le moment à construire explicitement la matrice documents x termes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Plugin\n",
      "Init Graph Optimizer\n",
      "Init Kernel\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "\n",
    "# note that the index construction is based on hashing so that a small size will inscrease the risk of collision\n",
    "vocab_size = 10000\n",
    "encoded_docs = [one_hot(d, vocab_size) for d in text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voyons ce que cela donne pour les premiers textes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...', 'Ok lar... Joking wif u oni...', \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\", 'U dun say so early hor... U c already then say...']\n",
      "[[7124, 1471, 8153, 2822, 8991, 7443, 88, 7225, 5414, 4764, 109, 4826, 9852, 8179, 2976, 672, 1963, 5963, 9379, 2381], [6757, 7225, 194, 2613, 3704, 8822], [2276, 1636, 7225, 3226, 3231, 3028, 8506, 6187, 8518, 38, 7468, 4039, 3538, 9923, 1328, 3718, 2315, 38, 6187, 7458, 6187, 8585, 1636, 435, 5187, 4626, 7934, 4813, 8557, 8597, 8187], [3704, 3038, 5147, 2569, 6173, 5467, 3704, 7842, 2435, 9033, 5147]]\n"
     ]
    }
   ],
   "source": [
    "print(text[0:4])\n",
    "print(encoded_docs[0:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour construire un MLP, on a besoin d'une entrée de taille fixe. Deux options :\n",
    "- utiliser un Bag of Words (BoW) avec des caractéristiques TF ou TFxIDF... (cf. TD 2)\n",
    "- garder l'ordre des mots et traiter directement la séquence, en intégrant ou non une couche de type \"word embedding\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 109 4826 9852 8179 2976  672 1963 5963 9379 2381]\n",
      " [6757 7225  194 2613 3704 8822    0    0    0    0]\n",
      " [8585 1636  435 5187 4626 7934 4813 8557 8597 8187]\n",
      " [3038 5147 2569 6173 5467 3704 7842 2435 9033 5147]]\n"
     ]
    }
   ],
   "source": [
    "#pad documents to a max length of 10 words\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_length = 10\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "print(padded_docs[0:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On crée les jeux d'entraînement / test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(padded_docs, y, \n",
    "                                                    train_size=0.7,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puis on construit une architecture légèrement différente d'ANN.\n",
    "\n",
    "On choisit ici de faire correspondre chaque mot (token), codé par son numéro (index), avec une ligne de la table enregistrant le codage dans un espace à k dimensions (cf. cours de text mining).\n",
    "\n",
    "Ensuite les \"embedding\" sont concaténés (opération \"flatten\") avant d'être passés à la couche suivante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 10, 10)            100000    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 808       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 100,817\n",
      "Trainable params: 100,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "def embedded_model(size_embedding):\n",
    "    model = Sequential()\n",
    "    # embedding layer\n",
    "    model.add(Embedding(vocab_size, size_embedding, input_length=max_length))\n",
    "    # let's concatenate the embedding vectors\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    # simple binary classification\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "#padded_model = embedded_model(vocab_size)\n",
    "padded_model = embedded_model(10)\n",
    "\n",
    "# summarize the model\n",
    "print(padded_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le suite est identique aux précédents notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "train_y = np.array(train_y)\n",
    "test_y = np.array(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-07 10:43:36.785735: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-12-07 10:43:36.785927: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2021-12-07 10:43:36.922031: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "122/122 [==============================] - 1s 5ms/step - loss: 0.5273 - acc: 0.8582\n",
      "Epoch 2/10\n",
      "122/122 [==============================] - 1s 5ms/step - loss: 0.1881 - acc: 0.9136\n",
      "Epoch 3/10\n",
      "122/122 [==============================] - 1s 5ms/step - loss: 0.0924 - acc: 0.9772\n",
      "Epoch 4/10\n",
      "122/122 [==============================] - 1s 5ms/step - loss: 0.0451 - acc: 0.9897\n",
      "Epoch 5/10\n",
      "122/122 [==============================] - 1s 5ms/step - loss: 0.0260 - acc: 0.9936\n",
      "Epoch 6/10\n",
      "122/122 [==============================] - 1s 5ms/step - loss: 0.0158 - acc: 0.9969\n",
      "Epoch 7/10\n",
      "122/122 [==============================] - 1s 5ms/step - loss: 0.0101 - acc: 0.9985\n",
      "Epoch 8/10\n",
      "122/122 [==============================] - 1s 5ms/step - loss: 0.0071 - acc: 0.9990\n",
      "Epoch 9/10\n",
      "122/122 [==============================] - 1s 5ms/step - loss: 0.0048 - acc: 0.9995\n",
      "Epoch 10/10\n",
      "122/122 [==============================] - 1s 5ms/step - loss: 0.0035 - acc: 0.9995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2a8652e50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "padded_model.fit(train_X, train_y, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-02 15:01:17.862061: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.386133\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = padded_model.evaluate(test_X, test_y, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
